# ============================================================================
# AutoScout24 Veri MadenciliÄŸi Vize Projesi
# ============================================================================
# Ã–zellikler: price, mileage_km, vehicle_age, power_hp,
#             transmission, fuel_category, country_code
# ============================================================================

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
from scipy import stats
from scipy.stats import chi2_contingency, f_oneway, skew, kurtosis
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from datetime import datetime
import os

warnings.filterwarnings("ignore")
plt.ioff()
plt.style.use("seaborn-v0_8-darkgrid")
sns.set_palette("husl")

# KlasÃ¶r oluÅŸtur
os.makedirs("../report/figures", exist_ok=True)

print("=" * 80)
print("          AutoScout24 Ä°kinci El AraÃ§ Veri MadenciliÄŸi Projesi")
print("                          VÄ°ZE Ã‡ALIÅMASI")
print("=" * 80)

# ============================================================================
# 1. VERÄ° YÃœKLEME
# ============================================================================
print("\n[ADIM 1] VERÄ° YÃœKLEME")
print("-" * 80)

df = pd.read_csv("../data/sampled_dataset_50percent.csv")
print(f"âœ“ Ã–rneklenmiÅŸ veri seti yÃ¼klendi: {len(df):,} kayÄ±t")
print(f"âœ“ Toplam Ã¶zellik sayÄ±sÄ±: {df.shape[1]}")

# SÃ¼tunlarÄ± seÃ§
required_columns = [
    "price",
    "mileage_km",
    "vehicle_age",
    "power_hp",
    "transmission",
    "fuel_category",
    "country_code",
]

df_selected = df[required_columns].copy()
print(f"âœ“ Analiz iÃ§in seÃ§ilen Ã¶zellikler: {len(required_columns)} adet")

# ============================================================================
# 2. VERÄ° TEMÄ°ZLEME
# ============================================================================
print("\n[ADIM 2] VERÄ° TEMÄ°ZLEME")
print("-" * 80)

initial_count = len(df_selected)
df_selected = df_selected.dropna()
print(
    f"âœ“ Eksik deÄŸerler temizlendi: {initial_count - len(df_selected):,} kayÄ±t kaldÄ±rÄ±ldÄ±"
)
print(f"âœ“ Temiz veri seti: {len(df_selected):,} kayÄ±t")

# SayÄ±sal ve kategorik sÃ¼tunlarÄ± ayÄ±r
numeric_cols = ["price", "mileage_km", "vehicle_age", "power_hp"]
categorical_cols = ["transmission", "fuel_category", "country_code"]

# ============================================================================
# 3. KEÅÄ°FSEL VERÄ° ANALÄ°ZÄ° (EDA) - VERÄ° MADENCÄ°LÄ°ÄÄ° TEKNÄ°KLERÄ°
# ============================================================================
print("\n[ADIM 3] KEÅÄ°FSEL VERÄ° ANALÄ°ZÄ° VE VERÄ° MADENCÄ°LÄ°ÄÄ° TEKNÄ°KLERÄ°")
print("=" * 80)

# -----------------------------------------------------------------------------
# 3.1 TANIMLAYICI Ä°STATÄ°STÄ°KLER (Mean, Median, Mode, Min, Max, Std, Var, vb.)
# -----------------------------------------------------------------------------
print("\n3.1 TANIMLAYICI Ä°STATÄ°STÄ°KLER")
print("-" * 80)

print("\nğŸ“Š Temel Ä°statistikler (5-SayÄ± Ã–zeti + Ortalama + Std):")
print(df_selected[numeric_cols].describe().round(2))

print("\nğŸ“Š DetaylÄ± Ä°statistiksel Ã–lÃ§Ã¼mler:")
print("=" * 80)
for col in numeric_cols:
    data = df_selected[col]
    print(f"\n{col.upper().replace('_', ' ')}:")
    print(f"  {'Mean (Ortalama)':<25}: {data.mean():>15,.2f}")
    print(f"  {'Median (Medyan)':<25}: {data.median():>15,.2f}")
    try:
        mode_val = data.mode()[0] if len(data.mode()) > 0 else "N/A"
        print(f"  {'Mode (Mod)':<25}: {mode_val:>15}")
    except:
        print(f"  {'Mode (Mod)':<25}: {'N/A':>15}")
    print(f"  {'Minimum':<25}: {data.min():>15,.2f}")
    print(f"  {'Maximum':<25}: {data.max():>15,.2f}")
    print(f"  {'Range (AralÄ±k)':<25}: {data.max() - data.min():>15,.2f}")
    print(f"  {'Std Dev (Std Sapma)':<25}: {data.std():>15,.2f}")
    print(f"  {'Variance (Varyans)':<25}: {data.var():>15,.2f}")
    print(f"  {'Q1 (1. Ã‡eyrek)':<25}: {data.quantile(0.25):>15,.2f}")
    print(f"  {'Q2 (2. Ã‡eyrek/Median)':<25}: {data.quantile(0.50):>15,.2f}")
    print(f"  {'Q3 (3. Ã‡eyrek)':<25}: {data.quantile(0.75):>15,.2f}")
    print(
        f"  {'IQR (Ã‡eyrekler ArasÄ±)':<25}: {data.quantile(0.75) - data.quantile(0.25):>15,.2f}"
    )
    print(f"  {'Skewness (Ã‡arpÄ±klÄ±k)':<25}: {skew(data):>15,.4f}")
    print(f"  {'Kurtosis (BasÄ±klÄ±k)':<25}: {kurtosis(data):>15,.4f}")
    cv = (data.std() / data.mean()) * 100
    print(f"  {'CV (Varyasyon KatsayÄ±sÄ±)':<25}: {cv:>14,.2f}%")

# -----------------------------------------------------------------------------
# 3.2 NORMALLÄ°K TESTLERÄ° (Shapiro-Wilk)
# -----------------------------------------------------------------------------
print("\n\n3.2 NORMALLÄ°K TESTLERÄ° (Shapiro-Wilk)")
print("-" * 80)
print("Hipotez:")
print("  H0: Veri normal daÄŸÄ±lÄ±ma sahiptir")
print("  H1: Veri normal daÄŸÄ±lÄ±ma sahip deÄŸildir")
print("  AnlamlÄ±lÄ±k: Î± = 0.05\n")

for col in numeric_cols:
    sample = df_selected[col].sample(min(5000, len(df_selected)), random_state=42)
    stat, p_value = stats.shapiro(sample)
    result = "âŒ Normal DEÄÄ°L (H0 red)" if p_value < 0.05 else "âœ… Normal (H0 kabul)"
    print(f"  {col:<15s}: p = {p_value:.6f}  â†’  {result}")

# -----------------------------------------------------------------------------
# 3.3 AYKIRIDEÄER ANALÄ°ZÄ° (IQR YÃ¶ntemi)
# -----------------------------------------------------------------------------
print("\n\n3.3 AYKIRI DEÄER ANALÄ°ZÄ° (IQR YÃ¶ntemi)")
print("-" * 80)
print("Kural: AykÄ±rÄ± deÄŸer = DeÄŸer < Q1 - 1.5Ã—IQR veya DeÄŸer > Q3 + 1.5Ã—IQR\n")

for col in numeric_cols:
    Q1 = df_selected[col].quantile(0.25)
    Q3 = df_selected[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    outliers = df_selected[(df_selected[col] < lower) | (df_selected[col] > upper)]
    count = len(outliers)
    pct = (count / len(df_selected)) * 100

    print(f"  {col}:")
    print(f"    Normal AralÄ±k: [{lower:,.2f}, {upper:,.2f}]")
    print(f"    AykÄ±rÄ± DeÄŸer : {count:,} kayÄ±t ({pct:.2f}%)\n")

# -----------------------------------------------------------------------------
# 3.4 KORELASYON ANALÄ°ZÄ° (Pearson) ve Ä°STATÄ°STÄ°KSEL ANLAMLILIK
# -----------------------------------------------------------------------------
print("\n3.4 KORELASYON ANALÄ°ZÄ° (Pearson)")
print("-" * 80)
print("Korelasyon Yorumlama:")
print("  |r| > 0.7  : GÃ¼Ã§lÃ¼ iliÅŸki")
print("  0.4< |r| <0.7 : Orta iliÅŸki")
print("  |r| < 0.4  : ZayÄ±f iliÅŸki\n")

corr_matrix = df_selected[numeric_cols].corr()
print("Korelasyon Matrisi:")
print(corr_matrix.round(3))

print("\nğŸ” GÃ¼Ã§lÃ¼/Orta Korelasyonlar (|r| > 0.3):")
for i in range(len(numeric_cols)):
    for j in range(i + 1, len(numeric_cols)):
        r_val = corr_matrix.iloc[i, j]
        if abs(r_val) > 0.3:
            col1, col2 = numeric_cols[i], numeric_cols[j]
            r, p = stats.pearsonr(df_selected[col1], df_selected[col2])
            sig = "***" if p < 0.001 else "**" if p < 0.01 else "*"
            direction = "Pozitif" if r > 0 else "Negatif"
            strength = "GÃ¼Ã§lÃ¼" if abs(r) > 0.7 else "Orta" if abs(r) > 0.4 else "ZayÄ±f"
            print(f"  {col1:15s} â†” {col2:15s}: r={r:>6.3f} {sig}")
            print(f"    â†’ {strength} {direction} Ä°liÅŸki (p<0.001)")

# -----------------------------------------------------------------------------
# 3.5 KATEGORÄ°K DEÄÄ°ÅKEN ANALÄ°ZÄ°
# -----------------------------------------------------------------------------
print("\n\n3.5 KATEGORÄ°K DEÄÄ°ÅKEN FREKANS ANALÄ°ZÄ°")
print("-" * 80)

for col in categorical_cols:
    vc = df_selected[col].value_counts()
    total = len(df_selected)
    print(f"\n{col.upper().replace('_', ' ')}:")
    print(f"  Toplam kategori: {len(vc)}")
    print(f"  En yaygÄ±n 10:")
    for i, (cat, count) in enumerate(vc.head(10).items(), 1):
        pct = (count / total) * 100
        print(f"    {i:2d}. {str(cat)[:20]:20s}: {count:>7,} ({pct:>5.2f}%)")

# -----------------------------------------------------------------------------
# 3.6 ANOVA TESTÄ° (Kategorik â†’ SayÄ±sal Ä°liÅŸki)
# -----------------------------------------------------------------------------
print("\n\n3.6 ANOVA TESTÄ° (Kategorik DeÄŸiÅŸken â†’ Fiyat Ä°liÅŸkisi)")
print("-" * 80)
print("Hipotez:")
print("  H0: Grup ortalamalarÄ± arasÄ±nda fark yoktur")
print("  H1: En az bir grup ortalamasÄ± farklÄ±dÄ±r")
print("  AnlamlÄ±lÄ±k: Î± = 0.05\n")

# Transmission â†’ Price
groups_trans = [
    df_selected[df_selected["transmission"] == cat]["price"].values
    for cat in df_selected["transmission"].unique()
]
f_stat, p_val = f_oneway(*groups_trans)
result = "âœ… AnlamlÄ± fark VAR" if p_val < 0.05 else "âŒ AnlamlÄ± fark YOK"
print(f"  Transmission â†’ Price:")
print(f"    F = {f_stat:.2f}, p = {p_val:.6f}")
print(f"    SonuÃ§: {result}\n")

# Fuel â†’ Price
groups_fuel = [
    df_selected[df_selected["fuel_category"] == cat]["price"].values
    for cat in df_selected["fuel_category"].unique()
]
f_stat, p_val = f_oneway(*groups_fuel)
result = "âœ… AnlamlÄ± fark VAR" if p_val < 0.05 else "âŒ AnlamlÄ± fark YOK"
print(f"  Fuel Category â†’ Price:")
print(f"    F = {f_stat:.2f}, p = {p_val:.6f}")
print(f"    SonuÃ§: {result}\n")

# Country â†’ Price
top_countries = df_selected["country_code"].value_counts().head(10).index
groups_country = [
    df_selected[df_selected["country_code"] == cat]["price"].values
    for cat in top_countries
]
f_stat, p_val = f_oneway(*groups_country)
result = "âœ… AnlamlÄ± fark VAR" if p_val < 0.05 else "âŒ AnlamlÄ± fark YOK"
print(f"  Country Code (Top 10) â†’ Price:")
print(f"    F = {f_stat:.2f}, p = {p_val:.6f}")
print(f"    SonuÃ§: {result}\n")

# -----------------------------------------------------------------------------
# 3.7 CHI-SQUARE TESTÄ° (Kategorik â†” Kategorik BaÄŸÄ±msÄ±zlÄ±k)
# -----------------------------------------------------------------------------
print("\n3.7 CHI-SQUARE BAÄIMSIZLIK TESTÄ° (Kategorik â†” Kategorik)")
print("-" * 80)
print("Hipotez:")
print("  H0: Ä°ki deÄŸiÅŸken baÄŸÄ±msÄ±zdÄ±r")
print("  H1: Ä°ki deÄŸiÅŸken arasÄ±nda iliÅŸki vardÄ±r")
print("  AnlamlÄ±lÄ±k: Î± = 0.05\n")

contingency = pd.crosstab(df_selected["transmission"], df_selected["fuel_category"])
chi2, p_val, dof, expected = chi2_contingency(contingency)
result = "âœ… Ä°liÅŸki VAR (baÄŸÄ±mlÄ±)" if p_val < 0.05 else "âŒ Ä°liÅŸki YOK (baÄŸÄ±msÄ±z)"
print(f"  Transmission â†” Fuel Category:")
print(f"    Ï‡Â² = {chi2:.2f}, p = {p_val:.6f}, df = {dof}")
print(f"    SonuÃ§: {result}\n")

# -----------------------------------------------------------------------------
# 3.8 GÃ–RSELLEÅTÄ°RMELER
# -----------------------------------------------------------------------------
print("\n3.8 GÃ–RSELLEÅTÄ°RMELER OLUÅTURULUYOR...")
print("-" * 80)

# Grafik 1: DaÄŸÄ±lÄ±mlar (Histogram + KDE)
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle("SayÄ±sal DeÄŸiÅŸkenlerin DaÄŸÄ±lÄ±mlarÄ±", fontsize=16, fontweight="bold")

for idx, col in enumerate(numeric_cols):
    ax = axes[idx // 2, idx % 2]
    ax.hist(
        df_selected[col],
        bins=50,
        color="skyblue",
        edgecolor="black",
        alpha=0.7,
        density=True,
    )

    # KDE ekle
    df_selected[col].plot(
        kind="kde", ax=ax, color="red", linewidth=2, secondary_y=False
    )

    median_val = df_selected[col].median()
    mean_val = df_selected[col].mean()
    ax.axvline(
        median_val,
        color="green",
        linestyle="--",
        linewidth=2,
        label=f"Median: {median_val:,.0f}",
    )
    ax.axvline(
        mean_val,
        color="orange",
        linestyle="--",
        linewidth=2,
        label=f"Mean: {mean_val:,.0f}",
    )

    ax.set_xlabel(col.replace("_", " ").title(), fontsize=11)
    ax.set_ylabel("YoÄŸunluk", fontsize=11)
    ax.set_title(
        f'{col.replace("_", " ").title()} DaÄŸÄ±lÄ±mÄ±', fontsize=12, fontweight="bold"
    )
    ax.legend(fontsize=9)
    ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig("../report/figures/01_distributions.png", dpi=300, bbox_inches="tight")
plt.close()
print("  âœ“ Grafik 1: DaÄŸÄ±lÄ±mlar (01_distributions.png)")

# Grafik 2: Box Plots - AykÄ±rÄ± DeÄŸer GÃ¶rselleÅŸtirme
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle("Box Plot - AykÄ±rÄ± DeÄŸer Analizi", fontsize=16, fontweight="bold")

for idx, col in enumerate(numeric_cols):
    ax = axes[idx // 2, idx % 2]
    bp = ax.boxplot(
        [df_selected[col]], labels=[col], patch_artist=True, showfliers=True
    )
    bp["boxes"][0].set_facecolor("lightcoral")
    bp["boxes"][0].set_alpha(0.7)

    Q1 = df_selected[col].quantile(0.25)
    Q3 = df_selected[col].quantile(0.75)
    median = df_selected[col].median()

    info_text = f"Q1: {Q1:,.0f}\nMedian: {median:,.0f}\nQ3: {Q3:,.0f}"
    ax.text(
        0.02,
        0.98,
        info_text,
        transform=ax.transAxes,
        fontsize=10,
        verticalalignment="top",
        bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.7),
    )

    ax.set_ylabel("DeÄŸer", fontsize=11)
    ax.set_title(f'{col.replace("_", " ").title()}', fontsize=12, fontweight="bold")
    ax.grid(alpha=0.3, axis="y")

plt.tight_layout()
plt.savefig("../report/figures/02_boxplots.png", dpi=300, bbox_inches="tight")
plt.close()
print("  âœ“ Grafik 2: Box Plots (02_boxplots.png)")

# Grafik 3: Korelasyon Matrisi
plt.figure(figsize=(10, 8))
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".3f",
    cmap="coolwarm",
    center=0,
    square=True,
    linewidths=1,
    cbar_kws={"shrink": 0.8},
    mask=mask,
)
plt.title("Korelasyon Matrisi (Pearson)", fontsize=14, fontweight="bold", pad=20)
plt.tight_layout()
plt.savefig("../report/figures/03_correlation.png", dpi=300, bbox_inches="tight")
plt.close()
print("  âœ“ Grafik 3: Korelasyon Matrisi (03_correlation.png)")

# Grafik 4: Scatter Matrix
from pandas.plotting import scatter_matrix

fig = plt.figure(figsize=(14, 14))
scatter_matrix(df_selected[numeric_cols], alpha=0.3, figsize=(14, 14), diagonal="kde")
plt.suptitle("Scatter Plot Matrisi", fontsize=16, fontweight="bold", y=0.995)
plt.tight_layout()
plt.savefig("../report/figures/04_scatter_matrix.png", dpi=300, bbox_inches="tight")
plt.close()
print("  âœ“ Grafik 4: Scatter Matrix (04_scatter_matrix.png)")

# Grafik 5: Kategorik DaÄŸÄ±lÄ±mlar
fig, axes = plt.subplots(1, 3, figsize=(16, 5))
fig.suptitle("Kategorik DeÄŸiÅŸken DaÄŸÄ±lÄ±mlarÄ±", fontsize=16, fontweight="bold")

for idx, col in enumerate(categorical_cols):
    vc = df_selected[col].value_counts().head(10)
    axes[idx].bar(
        range(len(vc)), vc.values, color=sns.color_palette("Set2")[idx], alpha=0.8
    )
    axes[idx].set_xticks(range(len(vc)))
    axes[idx].set_xticklabels(vc.index, rotation=45, ha="right")
    axes[idx].set_ylabel("Frekans", fontsize=11)
    axes[idx].set_title(
        f'{col.replace("_", " ").title()} (Top 10)', fontsize=12, fontweight="bold"
    )
    axes[idx].grid(alpha=0.3, axis="y")

    for i, v in enumerate(vc.values):
        axes[idx].text(i, v, f"{v:,}", ha="center", va="bottom", fontsize=9)

plt.tight_layout()
plt.savefig("../report/figures/05_categorical_dist.png", dpi=300, bbox_inches="tight")
plt.close()
print("  âœ“ Grafik 5: Kategorik DaÄŸÄ±lÄ±mlar (05_categorical_dist.png)")

# ============================================================================
# 4. KÃœMELEME ANALÄ°ZÄ° (K-MEANS)
# ============================================================================
print("\n\n[ADIM 4] KÃœMELEME ANALÄ°ZÄ° (K-MEANS)")
print("=" * 80)

# 4.1 Veri HazÄ±rlama
print("\n4.1 KÃ¼meleme iÃ§in Veri HazÄ±rlama")
print("-" * 80)

# Label Encoding
le_trans = LabelEncoder()
le_fuel = LabelEncoder()
le_country = LabelEncoder()

df_cluster = df_selected.copy()
df_cluster["transmission_enc"] = le_trans.fit_transform(df_selected["transmission"])
df_cluster["fuel_enc"] = le_fuel.fit_transform(df_selected["fuel_category"])
df_cluster["country_enc"] = le_country.fit_transform(df_selected["country_code"])

features = [
    "price",
    "mileage_km",
    "vehicle_age",
    "power_hp",
    "transmission_enc",
    "fuel_enc",
    "country_enc",
]

X = df_cluster[features].values
print(f"âœ“ Ã–zellik matrisi: {X.shape}")
print(f"  Ã–zellikler: {', '.join(features)}")

# Standardizasyon
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print(f"âœ“ Standardizasyon tamamlandÄ± (mean=0, std=1)")

# 4.2 Optimal K Bulma (k=10-400)
print("\n4.2 Optimal KÃ¼me SayÄ±sÄ± Bulma (k=10-400, 10'ar adÄ±mla)")
print("-" * 80)

k_range = list(range(10, 410, 10))
inertias = []
silhouettes = []

print("K-Means iterasyonlarÄ±:")
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)
    labels = kmeans.fit_predict(X_scaled)
    inertias.append(kmeans.inertia_)
    sil = silhouette_score(X_scaled, labels)
    silhouettes.append(sil)

    if k % 50 == 0 or k == k_range[0]:
        print(f"  k={k:3d}: Inertia={kmeans.inertia_:>12,.2f}, Silhouette={sil:>7.4f}")

# En iyi k
best_k = k_range[np.argmax(silhouettes)]
best_sil = max(silhouettes)

print(f"\nâœ… OPTIMAL K BULUNDU: k={best_k}")
print(f"   En yÃ¼ksek Silhouette Score: {best_sil:.4f}")

# Silhouette eÄŸrisi analizi
last_10_avg = np.mean(silhouettes[-10:])
print(f"\nğŸ“Š Silhouette EÄŸrisi Analizi:")
print(f"   En yÃ¼ksek skor: {best_sil:.4f} (k={best_k})")
print(f"   Son 10 deÄŸer ort: {last_10_avg:.4f}")
if last_10_avg < best_sil * 0.95:
    print(f"   âœ… EÄŸri tamamlanmÄ±ÅŸ - optimal k={best_k} gÃ¼venilir")
else:
    print(f"   âš ï¸  EÄŸri tam tamamlanmamÄ±ÅŸ - daha yÃ¼ksek k test edilebilir")

# Grafik 6: Optimal K SeÃ§imi
fig, axes = plt.subplots(1, 2, figsize=(16, 6))
fig.suptitle(
    f"Optimal KÃ¼me SayÄ±sÄ± Belirleme (k={best_k})", fontsize=16, fontweight="bold"
)

# Elbow
axes[0].plot(
    k_range, inertias, "o-", linewidth=2, markersize=6, color="blue", alpha=0.7
)
axes[0].set_xlabel("KÃ¼me SayÄ±sÄ± (k)", fontsize=12)
axes[0].set_ylabel("Inertia (WCSS)", fontsize=12)
axes[0].set_title("Elbow Method", fontsize=13, fontweight="bold")
axes[0].grid(alpha=0.3)

# Silhouette
axes[1].plot(
    k_range, silhouettes, "o-", linewidth=2, markersize=6, color="green", alpha=0.7
)
axes[1].axvline(
    best_k,
    color="red",
    linestyle="--",
    linewidth=2,
    label=f"Optimal k={best_k} (score={best_sil:.4f})",
)
axes[1].axhline(best_sil, color="orange", linestyle=":", linewidth=1, alpha=0.5)
axes[1].set_xlabel("KÃ¼me SayÄ±sÄ± (k)", fontsize=12)
axes[1].set_ylabel("Silhouette Score", fontsize=12)
axes[1].set_title("Silhouette Score EÄŸrisi", fontsize=13, fontweight="bold")
axes[1].legend(fontsize=10)
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig("../report/figures/06_optimal_k.png", dpi=300, bbox_inches="tight")
plt.close()
print("\n  âœ“ Grafik 6: Optimal K Analizi (06_optimal_k.png)")

# 4.3 Final K-Means Modeli
print(f"\n4.3 Final K-Means Modeli (k={best_k})")
print("-" * 80)

final_kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=20, max_iter=500)
cluster_labels = final_kmeans.fit_predict(X_scaled)
df_cluster["cluster"] = cluster_labels

final_sil = silhouette_score(X_scaled, cluster_labels)
print(f"âœ“ KÃ¼meleme tamamlandÄ±")
print(f"  Silhouette Score: {final_sil:.4f}")
print(f"  Inertia: {final_kmeans.inertia_:,.2f}")

print(f"\nğŸ“Š KÃ¼me DaÄŸÄ±lÄ±mÄ±:")
for i in range(best_k):
    count = np.sum(cluster_labels == i)
    pct = (count / len(cluster_labels)) * 100
    print(f"  KÃ¼me {i:2d}: {count:>6,} kayÄ±t ({pct:>5.2f}%)")

# 4.4 KÃ¼me Profilleri
print(f"\n4.4 KÃ¼me Profilleri (Ortalama DeÄŸerler)")
print("-" * 80)

cluster_profiles = df_cluster.groupby("cluster")[numeric_cols].mean()
print(cluster_profiles.round(2))

print(f"\nğŸ“‹ KÃ¼melerin Kategorik Ã–zellikleri:")
for i in range(best_k):
    cluster_data = df_cluster[df_cluster["cluster"] == i]
    trans_mode = (
        cluster_data["transmission"].mode()[0] if len(cluster_data) > 0 else "N/A"
    )
    fuel_mode = (
        cluster_data["fuel_category"].mode()[0] if len(cluster_data) > 0 else "N/A"
    )
    country_mode = (
        cluster_data["country_code"].mode()[0] if len(cluster_data) > 0 else "N/A"
    )

    print(f"\n  KÃ¼me {i:2d} ({len(cluster_data):,} kayÄ±t):")
    print(f"    Vites : {trans_mode}")
    print(f"    YakÄ±t : {fuel_mode}")
    print(f"    Ãœlke  : {country_mode}")

# Grafik 7: PCA GÃ¶rselleÅŸtirme
print(f"\n4.5 KÃ¼melerin GÃ¶rselleÅŸtirilmesi (PCA)")
print("-" * 80)

pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_scaled)

print(f"  PC1 varyans: {pca.explained_variance_ratio_[0]:.2%}")
print(f"  PC2 varyans: {pca.explained_variance_ratio_[1]:.2%}")
print(f"  Toplam     : {pca.explained_variance_ratio_.sum():.2%}")

plt.figure(figsize=(14, 10))

# 330 kÃ¼me iÃ§in colorbar kullanÄ±mÄ± (legend Ã§ok kalabalÄ±k olur)
scatter = plt.scatter(
    X_pca[:, 0],
    X_pca[:, 1],
    c=cluster_labels,
    cmap="Spectral",
    alpha=0.5,
    s=20,
    edgecolors="none",
)

centers_pca = pca.transform(final_kmeans.cluster_centers_)
plt.scatter(
    centers_pca[:, 0],
    centers_pca[:, 1],
    c="black",
    marker="X",
    s=200,
    edgecolors="white",
    linewidth=2,
    label=f"KÃ¼me Merkezleri (n={best_k})",
    zorder=10,
)

# Colorbar ekle (330 kÃ¼me iÃ§in legend yerine)
plt.colorbar(scatter, label="KÃ¼me ID", shrink=0.8)

plt.xlabel(f"PC1 ({pca.explained_variance_ratio_[0]:.1%} varyans)", fontsize=12)
plt.ylabel(f"PC2 ({pca.explained_variance_ratio_[1]:.1%} varyans)", fontsize=12)
plt.title(
    f"K-Means KÃ¼meleme - Mikro-Segmentasyon (k={best_k})",
    fontsize=14,
    fontweight="bold",
)
plt.legend(loc="upper right", framealpha=0.95, fontsize=11)
plt.grid(alpha=0.3, linestyle="--")
plt.tight_layout()
plt.savefig("../report/figures/07_clusters_pca.png", dpi=300, bbox_inches="tight")
plt.close()
print("  âœ“ Grafik 7: PCA GÃ¶rselleÅŸtirme (07_clusters_pca.png)")

# Grafik 8: KÃ¼me Merkezleri Heatmap (330 kÃ¼me iÃ§in sadece Ã¶rnek kÃ¼meleri gÃ¶ster)
plt.figure(figsize=(16, 10))
centers_df = pd.DataFrame(
    final_kmeans.cluster_centers_,
    columns=features,
    index=[f"K{i}" for i in range(best_k)],
)

# 330 kÃ¼me Ã§ok fazla - sadece her 10. kÃ¼meyi gÃ¶ster + ilk 5 ve son 5
if best_k > 50:
    sample_indices = list(range(0, min(10, best_k)))  # Ä°lk 10
    sample_indices += list(range(10, best_k, max(1, best_k // 30)))  # Her 10-15. kÃ¼me
    sample_indices += list(range(max(0, best_k - 10), best_k))  # Son 10
    sample_indices = sorted(set(sample_indices))[:40]  # Maksimum 40 kÃ¼me gÃ¶ster
    centers_sample = centers_df.iloc[sample_indices]
    title_text = f"KÃ¼me Merkezleri Ã–rneÄŸi (40/{best_k} kÃ¼me gÃ¶steriliyor)"
else:
    centers_sample = centers_df
    title_text = "KÃ¼me Merkezleri (Standardize DeÄŸerler)"

sns.heatmap(
    centers_sample.T,
    annot=False,  # 330 kÃ¼me iÃ§in annotation kapalÄ±
    cmap="RdYlGn",
    center=0,
    linewidths=0.5,
    cbar_kws={"shrink": 0.8, "label": "Standardize DeÄŸer"},
    vmin=-2,
    vmax=2,
)
plt.title(title_text, fontsize=14, fontweight="bold", pad=20)
plt.xlabel("KÃ¼me ID", fontsize=12)
plt.ylabel("Ã–zellik", fontsize=12)
plt.xticks(rotation=90, fontsize=8)
plt.yticks(fontsize=11)
plt.tight_layout()
plt.savefig("../report/figures/08_cluster_centers.png", dpi=300, bbox_inches="tight")
plt.close()
print("  âœ“ Grafik 8: KÃ¼me Merkezleri (08_cluster_centers.png)")

# Grafik 9: KÃ¼melere GÃ¶re Ã–zellik KarÅŸÄ±laÅŸtÄ±rmasÄ±
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle("KÃ¼melere GÃ¶re Ã–zellik KarÅŸÄ±laÅŸtÄ±rmalarÄ±", fontsize=16, fontweight="bold")

# 330 kÃ¼me iÃ§in renk paleti
boxplot_colors = plt.cm.Spectral(np.linspace(0, 1, best_k))

for idx, col in enumerate(numeric_cols):
    ax = axes[idx // 2, idx % 2]
    data_to_plot = [
        df_cluster[df_cluster["cluster"] == i][col].values for i in range(best_k)
    ]
    bp = ax.boxplot(
        data_to_plot,
        labels=[f"K{i}" for i in range(best_k)],
        patch_artist=True,
        showfliers=False,
    )

    for patch, color in zip(bp["boxes"], boxplot_colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)

    ax.set_ylabel(col.replace("_", " ").title(), fontsize=11)
    ax.set_xlabel("KÃ¼me", fontsize=11)
    ax.set_title(
        f'{col.replace("_", " ").title()} DaÄŸÄ±lÄ±mÄ±', fontsize=12, fontweight="bold"
    )
    ax.grid(alpha=0.3, axis="y")
    # 330 kÃ¼me iÃ§in x-tick etiketlerini seyrekleÅŸtir
    if best_k > 50:
        ax.set_xticks(range(0, best_k, max(1, best_k // 10)))
        ax.set_xticklabels(
            [f"K{i}" for i in range(0, best_k, max(1, best_k // 10))],
            rotation=45,
            fontsize=8,
        )

plt.tight_layout()
plt.savefig("../report/figures/09_cluster_comparison.png", dpi=300, bbox_inches="tight")
plt.close()
print("  âœ“ Grafik 9: KÃ¼me KarÅŸÄ±laÅŸtÄ±rmalarÄ± (09_cluster_comparison.png)")

# ============================================================================
# 5. KÃœMELER ÃœZERÄ°NDE VERÄ° MADENCÄ°LÄ°ÄÄ° TEKNÄ°KLERÄ°
# ============================================================================
print("\n\n[ADIM 5] KÃœMELER ÃœZERÄ°NDE VERÄ° MADENCÄ°LÄ°ÄÄ° ANALÄ°ZÄ°")
print("=" * 80)

print("\n5.1 Her KÃ¼me Ä°Ã§in Ä°statistiksel Analiz")
print("-" * 80)

for cluster_id in range(best_k):
    cluster_data = df_cluster[df_cluster["cluster"] == cluster_id]
    print(f"\n{'=' * 80}")
    print(
        f"KÃœME {cluster_id} ANALÄ°ZÄ° ({len(cluster_data):,} kayÄ±t - %{len(cluster_data)/len(df_cluster)*100:.1f})"
    )
    print(f"{'=' * 80}")

    # TanÄ±mlayÄ±cÄ± istatistikler
    print(f"\nğŸ“Š SayÄ±sal DeÄŸiÅŸken Ä°statistikleri:")
    for col in numeric_cols:
        data = cluster_data[col]
        print(f"\n  {col.upper()}:")
        print(f"    Mean   : {data.mean():>12,.2f}")
        print(f"    Median : {data.median():>12,.2f}")
        print(f"    Std    : {data.std():>12,.2f}")
        print(f"    Min    : {data.min():>12,.2f}")
        print(f"    Max    : {data.max():>12,.2f}")

    # Kategorik Ã¶zellikler
    print(f"\nğŸ“‹ Kategorik DeÄŸiÅŸken DaÄŸÄ±lÄ±mlarÄ±:")
    for col in categorical_cols:
        top_3 = cluster_data[col].value_counts().head(3)
        print(f"\n  {col.upper()} (Top 3):")
        for cat, count in top_3.items():
            pct = (count / len(cluster_data)) * 100
            print(f"    {str(cat)[:20]:20s}: {count:>5,} ({pct:>5.1f}%)")

    # KÃ¼me iÃ§i korelasyon
    print(f"\nğŸ”— KÃ¼me Ä°Ã§i Korelasyonlar (|r| > 0.3):")
    cluster_corr = cluster_data[numeric_cols].corr()
    found_corr = False
    for i in range(len(numeric_cols)):
        for j in range(i + 1, len(numeric_cols)):
            r_val = cluster_corr.iloc[i, j]
            if abs(r_val) > 0.3:
                print(
                    f"    {numeric_cols[i]:15s} â†” {numeric_cols[j]:15s}: r = {r_val:>6.3f}"
                )
                found_corr = True
    if not found_corr:
        print("    (GÃ¼Ã§lÃ¼ korelasyon bulunamadÄ±)")

# KÃ¼meler arasÄ± karÅŸÄ±laÅŸtÄ±rma (ANOVA)
print(f"\n\n5.2 KÃ¼meler ArasÄ± ANOVA Testi")
print("-" * 80)
print("Hipotez: H0: TÃ¼m kÃ¼melerin ortalamalarÄ± eÅŸittir\n")

for col in numeric_cols:
    groups = [df_cluster[df_cluster["cluster"] == i][col].values for i in range(best_k)]
    f_stat, p_val = f_oneway(*groups)
    result = "âœ… KÃ¼meler FARKLI" if p_val < 0.05 else "âŒ KÃ¼meler benzer"
    print(f"  {col:15s}: F={f_stat:>8.2f}, p={p_val:.6f}  â†’  {result}")

# ============================================================================
# 6. SONUÃ‡LARI KAYDETME
# ============================================================================
print("\n\n[ADIM 6] SONUÃ‡LARI KAYDETME")
print("=" * 80)

# KÃ¼melenmiÅŸ veri
df_cluster.to_csv("../data/clustered_data.csv", index=False)
print("âœ“ KÃ¼melenmiÅŸ veri: ../data/clustered_data.csv")

# KÃ¼me istatistikleri
cluster_stats = df_cluster.groupby("cluster").agg(
    {
        "price": ["count", "mean", "median", "std", "min", "max"],
        "mileage_km": ["mean", "median", "std"],
        "vehicle_age": ["mean", "median", "std"],
        "power_hp": ["mean", "median", "std"],
    }
)
cluster_stats.to_csv("../data/cluster_statistics.csv")
print("âœ“ KÃ¼me istatistikleri: ../data/cluster_statistics.csv")

# Ã–zet rapor
with open("../data/analysis_summary.txt", "w", encoding="utf-8") as f:
    f.write("=" * 80 + "\n")
    f.write("AutoScout24 Veri MadenciliÄŸi Vize Projesi - Analiz Ã–zeti\n")
    f.write("=" * 80 + "\n\n")

    f.write(f"VERÄ° SETÄ° BÄ°LGÄ°LERÄ°:\n")
    f.write(f"  Toplam KayÄ±t    : {len(df_cluster):,}\n")
    f.write(f"  Ã–zellik SayÄ±sÄ±  : {len(features)}\n")
    f.write(f"  SayÄ±sal DeÄŸiÅŸken: {len(numeric_cols)}\n")
    f.write(f"  Kategorik DeÄŸ.  : {len(categorical_cols)}\n\n")

    f.write(f"KÃœMELEME SONUÃ‡LARI:\n")
    f.write(f"  Optimal K       : {best_k}\n")
    f.write(f"  Silhouette Score: {final_sil:.4f}\n")
    f.write(f"  Inertia         : {final_kmeans.inertia_:,.2f}\n")
    f.write(f"  PCA Varyans     : {pca.explained_variance_ratio_.sum():.2%}\n\n")

    f.write(f"KÃœME PROFÄ°LLERÄ° (Ortalama DeÄŸerler):\n")
    f.write("=" * 80 + "\n")
    f.write(cluster_profiles.to_string())
    f.write("\n\n")

    f.write(f"KÃœME DAÄILIMLARI:\n")
    for i in range(best_k):
        count = np.sum(cluster_labels == i)
        pct = (count / len(cluster_labels)) * 100
        f.write(f"  KÃ¼me {i:2d}: {count:>6,} kayÄ±t ({pct:>5.2f}%)\n")

print("âœ“ Analiz Ã¶zeti: ../data/analysis_summary.txt")

# ============================================================================
# FÄ°NAL
# ============================================================================
print("\n" + "=" * 80)
print("                        ANALÄ°Z TAMAMLANDI!")
print("=" * 80)
print(f"\nğŸ“Š VERÄ° SETÄ°:")
print(f"   Toplam kayÄ±t: {len(df_cluster):,}")
print(f"   Ã–zellik sayÄ±sÄ±: {len(features)}")
print(f"\nğŸ¯ KÃœMELEME:")
print(f"   Optimal K: {best_k}")
print(f"   Silhouette Score: {final_sil:.4f}")
print(f"   K aralÄ±ÄŸÄ± test: {k_range[0]}-{k_range[-1]}")
print(f"\nğŸ“ Ã‡IKTILAR:")
print(f"   Grafikler: ../report/figures/ ({9} adet)")
print(f"   Veri: ../data/clustered_data.csv")
print(f"   Ä°statistikler: ../data/cluster_statistics.csv")
print(f"   Ã–zet: ../data/analysis_summary.txt")
print("\n" + "=" * 80)
print("SÄ±radaki adÄ±m: Makale yazÄ±mÄ±")
print("=" * 80 + "\n")
